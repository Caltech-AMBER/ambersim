"""
This type stub file was generated by pyright.
"""

import enum

import dm_env

"""RL environment classes for Composer tasks."""
_STEPS_LOGGING_INTERVAL = ...
HOOK_NAMES = ...
_empty_function = ...
_EMPTY_CODE = ...
_EMPTY_WITH_DOCSTRING_CODE = ...

class ObservationPadding(enum.Enum):
    INITIAL_VALUE = ...
    ZERO = ...

class EpisodeInitializationError(RuntimeError):
    """Raised by a `composer.Task` when it fails to initialize an episode."""

    ...

class _Hook:
    __slots__ = ...
    def __init__(self) -> None: ...

class _EnvironmentHooks:
    """Helper object that scans and memoizes various hooks in a task.

    This object exist to ensure that we do not incur a substantial overhead in
    calling empty entity hooks in more complicated tasks.
    """

    __slots__ = ...
    def __init__(self, task) -> None: ...
    def refresh_entity_hooks(self):  # -> None:
        """Scans and memoizes all non-trivial entity hooks."""
        ...
    def add_extra_hook(self, hook_name, hook_callable):  # -> None:
        ...
    def initialize_episode_mjcf(self, random_state):  # -> None:
        ...
    def after_compile(self, physics, random_state):  # -> None:
        ...
    def initialize_episode(self, physics, random_state):  # -> None:
        ...
    def before_step(self, physics, action, random_state):  # -> None:
        ...
    def before_substep(self, physics, action, random_state):  # -> None:
        ...
    def after_substep(self, physics, random_state):  # -> None:
        ...
    def after_step(self, physics, random_state):  # -> None:
        ...

class _CommonEnvironment:
    """Common components for RL environments."""

    def __init__(
        self,
        task,
        time_limit=...,
        random_state=...,
        n_sub_steps=...,
        raise_exception_on_physics_error=...,
        strip_singleton_obs_buffer_dim=...,
        delayed_observation_padding=...,
        legacy_step: bool = ...,
    ) -> None:
        """Initializes an instance of `_CommonEnvironment`.

        Args:
          task: Instance of `composer.base.Task`.
          time_limit: (optional) A float, the time limit in seconds beyond which an
            episode is forced to terminate.
          random_state: Optional, either an int seed or an `np.random.RandomState`
            object. If None (default), the random number generator will self-seed
            from a platform-dependent source of entropy.
          n_sub_steps: (DEPRECATED) An integer, number of physics steps to take per
            agent control step. New code should instead override the
            `control_substep` property of the task.
          raise_exception_on_physics_error: (optional) A boolean, indicating whether
            `PhysicsError` should be raised as an exception. If `False`, physics
            errors will result in the current episode being terminated with a
            warning logged, and a new episode started.
          strip_singleton_obs_buffer_dim: (optional) A boolean, if `True`,
            the array shape of observations with `buffer_size == 1` will not have a
            leading buffer dimension.
          delayed_observation_padding: (optional) An `ObservationPadding` enum value
            specifying the padding behavior of the initial buffers for delayed
            observables. If `ZERO` then the buffer is initially filled with zeroes.
            If `INITIAL_VALUE` then the buffer is initially filled with the first
            observation values.
          legacy_step: If True, steps the state with up-to-date position and
            velocity dependent fields. See Page 6 of
            https://arxiv.org/abs/2006.12983 for more information.
        """
        ...
    def add_extra_hook(self, hook_name, hook_callable):  # -> None:
        ...
    @property
    def physics(self):  # -> Any | None:
        """Returns a `weakref.ProxyType` pointing to the current `mjcf.Physics`.

        Note that the underlying `mjcf.Physics` will be destroyed whenever the MJCF
        model is recompiled. It is therefore unsafe for external objects to hold a
        reference to `environment.physics`. Attempting to access attributes of a
        dead `Physics` instance will result in a `ReferenceError`.
        """
        ...
    @property
    def task(self): ...
    @property
    def random_state(self):  # -> RandomState:
        ...
    def control_timestep(self):
        """Returns the interval between agent actions in seconds."""
        ...

class Environment(_CommonEnvironment, dm_env.Environment):
    """Reinforcement learning environment for Composer tasks."""

    def __init__(
        self,
        task,
        time_limit=...,
        random_state=...,
        n_sub_steps=...,
        raise_exception_on_physics_error=...,
        strip_singleton_obs_buffer_dim=...,
        max_reset_attempts=...,
        delayed_observation_padding=...,
        legacy_step: bool = ...,
    ) -> None:
        """Initializes an instance of `Environment`.

        Args:
          task: Instance of `composer.base.Task`.
          time_limit: (optional) A float, the time limit in seconds beyond which
            an episode is forced to terminate.
          random_state: (optional) an int seed or `np.random.RandomState` instance.
          n_sub_steps: (DEPRECATED) An integer, number of physics steps to take per
            agent control step. New code should instead override the
            `control_substep` property of the task.
          raise_exception_on_physics_error: (optional) A boolean, indicating whether
            `PhysicsError` should be raised as an exception. If `False`, physics
            errors will result in the current episode being terminated with a
            warning logged, and a new episode started.
          strip_singleton_obs_buffer_dim: (optional) A boolean, if `True`,
            the array shape of observations with `buffer_size == 1` will not have a
            leading buffer dimension.
          max_reset_attempts: (optional) Maximum number of times to try resetting
            the environment. If an `EpisodeInitializationError` is raised
            during this process, an environment reset is reattempted up to this
            number of times. If this count is exceeded then the most recent
            exception will be allowed to propagate. Defaults to 1, i.e. no failure
            is allowed.
          delayed_observation_padding: (optional) An `ObservationPadding` enum value
            specifying the padding behavior of the initial buffers for delayed
            observables. If `ZERO` then the buffer is initially filled with zeroes.
            If `INITIAL_VALUE` then the buffer is initially filled with the first
            observation values.
          legacy_step: If True, steps the state with up-to-date position and
            velocity dependent fields.
        """
        ...
    def reset(self):  # -> TimeStep:
        ...
    def step_spec(self):  # -> TimeStep:
        """DEPRECATED: please use `reward_spec` and `discount_spec` instead."""
        ...
    def step(self, action):  # -> TimeStep:
        """Updates the environment using the action and returns a `TimeStep`."""
        ...
    def action_spec(self):
        """Returns the action specification for this environment."""
        ...
    def reward_spec(self):  # -> Array:
        """Describes the reward returned by this environment.

        This will be the output of `self.task.reward_spec()` if it is not None,
        otherwise it will be the default spec returned by
        `dm_env.Environment.reward_spec()`.

        Returns:
          A `specs.Array` instance, or a nested dict, list or tuple of
          `specs.Array`s.
        """
        ...
    def discount_spec(self):  # -> BoundedArray:
        """Describes the discount returned by this environment.

        This will be the output of `self.task.discount_spec()` if it is not None,
        otherwise it will be the default spec returned by
        `dm_env.Environment.discount_spec()`.

        Returns:
          A `specs.Array` instance, or a nested dict, list or tuple of
          `specs.Array`s.
        """
        ...
    def observation_spec(self):  # -> Any:
        """Returns the observation specification for this environment.

        Returns:
          An `OrderedDict` mapping observation name to `specs.Array` containing
          observation shape and dtype.
        """
        ...
