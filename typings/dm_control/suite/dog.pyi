"""
This type stub file was generated by pyright.
"""

from dm_control import mujoco
from dm_control.suite import base

"""Dog Domain."""
_DEFAULT_TIME_LIMIT = ...
_CONTROL_TIMESTEP = ...
_MAX_UPRIGHT_ANGLE = ...
_MIN_UPRIGHT_COSINE = ...
_STAND_HEIGHT_FRACTION = ...
_EXCESSIVE_LIMIT_TORQUES = ...
_WALK_SPEED = ...
_TROT_SPEED = ...
_RUN_SPEED = ...
_HINGE_TYPE = ...
_LIMIT_TYPE = ...
SUITE = ...
_ASSET_DIR = ...

def make_model(floor_size, remove_ball):
    """Sets floor size, removes ball and walls (Stand and Move tasks)."""
    ...

def get_model_and_assets(floor_size=..., remove_ball=...):  # -> tuple[Unknown, dict[str, Any]]:
    """Returns a tuple containing the model XML string and a dict of assets."""
    ...

@SUITE.add("no_reward_visualization")
def stand(time_limit=..., random=..., environment_kwargs=...):  # -> Environment:
    """Returns the Stand task."""
    ...

@SUITE.add("no_reward_visualization")
def walk(time_limit=..., random=..., environment_kwargs=...):  # -> Environment:
    """Returns the Walk task."""
    ...

@SUITE.add("no_reward_visualization")
def trot(time_limit=..., random=..., environment_kwargs=...):  # -> Environment:
    """Returns the Trot task."""
    ...

@SUITE.add("no_reward_visualization")
def run(time_limit=..., random=..., environment_kwargs=...):  # -> Environment:
    """Returns the Run task."""
    ...

@SUITE.add("no_reward_visualization", "hard")
def fetch(time_limit=..., random=..., environment_kwargs=...):  # -> Environment:
    """Returns the Fetch task."""
    ...

class Physics(mujoco.Physics):
    """Physics simulation with additional features for the Dog domain."""

    def torso_pelvis_height(self):
        """Returns the height of the torso."""
        ...
    def z_projection(self):  # -> NDArray[Unknown]:
        """Returns rotation-invariant projection of local frames to the world z."""
        ...
    def upright(self):  # -> ndarray[Any, dtype[Unknown]]:
        """Returns projection from local z-axes to the z-axis of world."""
        ...
    def center_of_mass_velocity(self):
        """Returns the velocity of the center-of-mass."""
        ...
    def torso_com_velocity(self):
        """Returns the velocity of the center-of-mass in the torso frame."""
        ...
    def com_forward_velocity(self):
        """Returns the com velocity in the torso's forward direction."""
        ...
    def joint_angles(self):
        """Returns the configuration of all hinge joints (skipping free joints)."""
        ...
    def joint_velocities(self):
        """Returns the velocity of all hinge joints (skipping free joints)."""
        ...
    def inertial_sensors(self):
        """Returns inertial sensor readings."""
        ...
    def touch_sensors(self):
        """Returns touch readings."""
        ...
    def foot_forces(self):
        """Returns touch readings."""
        ...
    def ball_in_head_frame(self):  # -> NDArray[Unknown | Any]:
        """Returns the ball position and velocity in the frame of the head."""
        ...
    def target_in_head_frame(self):
        """Returns the target position in the frame of the head."""
        ...
    def ball_to_mouth_distance(self):  # -> floating[Any]:
        """Returns the distance from the ball to the mouth."""
        ...
    def ball_to_target_distance(self):  # -> floating[Any]:
        """Returns the distance from the ball to the target."""
        ...

class Stand(base.Task):
    """A dog stand task generating upright posture."""

    def __init__(self, random=..., observe_reward_factors=...) -> None:
        """Initializes an instance of `Stand`.

        Args:
          random: Optional, either a `numpy.random.RandomState` instance, an
            integer seed for creating a new `RandomState`, or None to select a seed
            automatically (default).
          observe_reward_factors: Boolean, whether the factorised reward is a
            key in the observation dict returned to the agent.
        """
        ...
    def initialize_episode(self, physics):  # -> None:
        """Randomizes initial root velocities and actuator states.

        Args:
          physics: An instance of `Physics`.

        """
        ...
    def get_observation_components(self, physics):  # -> OrderedDict[Unknown, Unknown]:
        """Returns the observations for the Stand task."""
        ...
    def get_observation(self, physics):  # -> OrderedDict[Unknown, Unknown]:
        """Returns the observation, possibly adding reward factors."""
        ...
    def get_reward_factors(self, physics):  # -> NDArray[Any]:
        """Returns the factorized reward."""
        ...
    def get_reward(self, physics):  # -> int_:
        """Returns the reward, product of reward factors."""
        ...

class Move(Stand):
    """A dog move task for generating locomotion."""

    def __init__(self, move_speed, random, observe_reward_factors=...) -> None:
        """Initializes an instance of `Move`.

        Args:
          move_speed: A float. Specifies a target horizontal velocity.
          random: Optional, either a `numpy.random.RandomState` instance, an
            integer seed for creating a new `RandomState`, or None to select a seed
            automatically (default).
          observe_reward_factors: Boolean, whether the factorised reward is a
            component of the observation dict.
        """
        ...
    def get_reward_factors(self, physics):  # -> NDArray[Any]:
        """Returns the factorized reward."""
        ...

class Fetch(Stand):
    """A dog fetch task to fetch a thrown ball."""

    def __init__(self, random, observe_reward_factors=...) -> None:
        """Initializes an instance of `Move`.

        Args:
          random: Optional, either a `numpy.random.RandomState` instance, an
            integer seed for creating a new `RandomState`, or None to select a seed
            automatically (default).
          observe_reward_factors: Boolean, whether the factorised reward is a
            component of the observation dict.
        """
        ...
    def initialize_episode(self, physics):  # -> None:
        ...
    def get_observation_components(self, physics):  # -> OrderedDict[Unknown, Unknown]:
        """Returns the common observations for the Stand task."""
        ...
    def get_reward_factors(self, physics):  # -> NDArray[Any]:
        """Returns a reward to the agent."""
        ...
