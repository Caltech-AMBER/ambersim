{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8b662-c50c-4125-9b57-b6fae8791411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import jax\n",
    "import os\n",
    "import time\n",
    "# jax.config.update('jax_platform_name', \"cpu\")\n",
    "\n",
    "from datetime import datetime\n",
    "from jax import numpy as jp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
    "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
    "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
    "    f.write(\"\"\"{\n",
    "    \"file_format_version\" : \"1.0.0\",\n",
    "    \"ICD\" : {\n",
    "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl\n",
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false\n",
    "import flax\n",
    "from brax import envs\n",
    "from brax.io import model\n",
    "from brax.io import json\n",
    "from brax.io import html\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "\n",
    "import distutils.util\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "\n",
    "import jax.numpy as jnp\n",
    "#@title Import packages for plotting and creating graphics\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Callable, NamedTuple, Optional, Union, List\n",
    "\n",
    "# Graphics and plotting.\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "import functools\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)\n",
    "\n",
    "from ambersim.envs.exo import Exo\n",
    "#\n",
    "env_name = \"exo\"\n",
    "envs.register_environment(\"exo\", Exo)\n",
    "env = envs.get_environment(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a455ccb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_networks_factory = functools.partial(\n",
    "    ppo_networks.make_ppo_networks,\n",
    "        policy_hidden_layer_sizes=(64,64,64,64))\n",
    "train_fn = functools.partial(\n",
    "      ppo.train,\n",
    "      num_timesteps=1000, num_evals=10, reward_scaling=1,\n",
    "      episode_length=1000, normalize_observations=True,\n",
    "      action_repeat=1, unroll_length=20, num_minibatches=8, gae_lambda=0.95,\n",
    "      num_updates_per_batch=4, discounting=0.99, learning_rate=1e-4,\n",
    "      entropy_cost=1e-2, num_envs=2048, batch_size=1024,\n",
    "      network_factory=make_networks_factory,\n",
    "      num_resets_per_eval=10,\n",
    "      seed=0)\n",
    "\n",
    "def progress(num_steps, metrics):\n",
    "  times.append(datetime.now())\n",
    "  x_data.append(num_steps)\n",
    "  y_data.append(metrics['eval/episode_reward'])\n",
    "  ydataerr.append(metrics['eval/episode_reward_std'])\n",
    "\n",
    "  plt.xlim([0, train_fn.keywords['num_timesteps'] * 1.25])\n",
    "  plt.ylim([min_y, max_y])\n",
    "\n",
    "  plt.xlabel('# environment steps')\n",
    "  plt.ylabel('reward per episode')\n",
    "  plt.title(f'y={y_data[-1]:.3f}')\n",
    "\n",
    "  plt.errorbar(\n",
    "      x_data, y_data, yerr=ydataerr)\n",
    "  plt.show()\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "ydataerr = []\n",
    "times = [datetime.now()]\n",
    "max_y, min_y = 1, 0\n",
    "\n",
    "# Reset environments since internals may be overwritten by tracers from the\n",
    "# domain randomization function.\n",
    "env = envs.get_environment(env_name)\n",
    "eval_env = envs.get_environment(env_name)\n",
    "make_inference_fn, params, _= train_fn(environment=env,\n",
    "                                       progress_fn=progress,\n",
    "                                       eval_env=eval_env)\n",
    "\n",
    "print(f'time to jit: {times[1] - times[0]}')\n",
    "print(f'time to train: {times[-1] - times[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4954727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Save Model\n",
    "model_path = 'policies/mjx_brax_policy'\n",
    "model.save_params(model_path, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde64408",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.load_params(model_path)\n",
    "\n",
    "inference_fn = make_inference_fn(params)\n",
    "jit_inference_fn = jax.jit(inference_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368e109-3d7e-440b-a643-351f3f36ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_env = envs.get_environment(env_name)\n",
    "jit_reset = jax.jit(eval_env.reset)\n",
    "jit_step = jax.jit(eval_env.step)\n",
    "\n",
    "rollout = []\n",
    "actions = []\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = jit_env_reset(rng)\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    rollout.append(state)\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "    state = jit_env_step(state, act)\n",
    "    end = time.time()\n",
    "    print(f\"step time: {end - start}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f58481-f611-4dec-a4b7-1f55276ed1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco\n",
    "from mujoco import mjx\n",
    "def get_image(renderer, env, state, camera):\n",
    "    d = mujoco.MjData(env.model)\n",
    "    # write the mjx.Data into an mjData object\n",
    "    mjx.device_get_into(d, state)\n",
    "    mujoco.mj_forward(env.model, d)\n",
    "    \n",
    "    camera.lookat[0] = d.qpos[0]\n",
    "    camera.lookat[1] = d.qpos[1]\n",
    "    \n",
    "    # use the mjData object to update the renderer\n",
    "    \n",
    "    renderer.update_scene(d, camera=camera)\n",
    "\n",
    "    # time = d.time\n",
    "    # curTime = f\"Time = {time:.3f}\"\n",
    "    # mujoco.mjr_overlay(mujoco.mjtFont.mjFONT_NORMAL,mujoco.mjtGridPos.mjGRID_TOPLEFT,renderer._rect,curTime,'test',renderer._mjr_context)\n",
    "\n",
    "    return renderer.render()\n",
    "\n",
    "env.getRender()\n",
    "images = []\n",
    "for i in range(len(rollout)):\n",
    "    temp_State = rollout[i].pipeline_state\n",
    "    images.append(get_image(env.renderer,env,temp_State,env.camera))\n",
    "\n",
    "media.show_video(images, fps=1.0 / env.dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65171274-47d4-41ff-8a76-422693fd5216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_file = 'exo_ppo.mp4'\n",
    "# Save the video\n",
    "media.write_video(output_file, images,fps=30) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambersim",
   "language": "python",
   "name": "ambersim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
